---
title: "Document Classification Case Study: Kiva Loans"
author: "Dr. Stephen W. Thomas, Queen's University"
date: "July 14, 2017"
output:
  pdf_document:
    highlight: pygments
    number_sections: yes
    toc: no
    toc_depth: '2'
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning=FALSE, message=FALSE, fig.align='center')
```

```{r}
library(tidyverse)
library(scales)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(MLmetrics)
library(topicmodels)
library(tidytext)
library(knitr)
library(kableExtra)
```



\hrulefill
<hr/>

```{r, echo=FALSE, out.width = "150px"}
knitr::include_graphics("kivaloans.jpg")
```

# Introduction

[Kiva Microfunds](https://www.kiva.org/) is a non-profit that allows people to lend money to low-income entrepreneurs and students around the world. Started in 2005, Kiva has crowd-funded millions of loans with a repayment rate of 98% to 99%.


In additional to traditional demographic data, Kiva includes personal stories on each borrower because they want lenders to connect with the borrowers on a human level. An example:

*Evelyn is 40 years old and married with 3 kids. She is in the Karura Hope women group and her life has been changed by the first KIVA loan she received last year which she is completing this quarter. Before she received the loan, she used to sell 9 litres of milk daily to local residents. After receiving the loan she bought iron sheets, five cement packets, one lorry of sand, some ballast and animal feed for her cows and improved her cow shed. Today she sells a daily average of 40 litres of milk to the Kiamba Dairy cooperative society, which is affiliated to the Kenya Cooperative Creameries at a cost of USD 0.28 per litre. Her daily farming has really grown. Evelyn intends to buy another dairy cow and a tank of water for home consumption and for her cows. She intends to repay in monthly installments.*

Despite her uplifting story, and her previous successful loan, Evelyn defaulted on her next loan of 900 USD.

In this case study, we will explore past Kiva loans and build a prediction model (in particular, a decision tree classifier) to predict which future borrowers will pay back loans, and which will default. A key question we will explore is: does adding text (i.e., the personal stories) to the prediction model increase or decrease its prediction power?

This case study will provide lots of data and graphs, but is intentionally light on commentary, analysis, and decision making. That's your job!


## Case Discussion Questions

At the end of this case study, we will have a group discussion around the following questions:

1. Does text data help in predicting which loan seeker will default?
2. Which words are most biased towards defaulting? Is this expected/intuitive?
3. According to the decision tree prediction models, what variables best predict a default?
4. As a decision maker, would you recommend the use of textual data in your prediction models?


# Kiva Background

The key terms in the Kiva world are:

- **The loan**. A loan is the most important data object at Kiva. Most other objects are in some way related to a loan.

- **The borrower**. A borrower is someone who has requested a loan. Borrowers are often
referred to as "businesses or "entrepreneurs" in order to emphasize the entrepreneurial spirit of
these individuals who work to make a difference in their lives. 

- **The lender**. A lender is a user registered on the Kiva website for the purposes of lending money and
participating in the community. Some lenders have public profiles, known as lender pages, on
the Kiva website, where they can share details about their activities and mission. Most lenders,
however, refrain from displaying their public information and are referred to as “anonymous.”

- **The partner.** A partner, or Kiva field partner, is usually a microfinance institution with which Kiva works to
find and fund loans. Every loan at Kiva is offered by a partner to a borrower, and the partner
works with Kiva to get funding for that loan from lenders.



<!--
# Loading the Data
-->


```{r, include=FALSE}
df <- read_csv("kiva.csv")
```


```{r, include=FALSE}
str(df)
df$id = 1:nrow(df)
df$status = as.factor(df$status)
df$sector = as.factor(df$sector)
df$country = as.factor(df$country)
df$gender = as.factor(df$gender)
df$nonpayment = as.factor(df$nonpayment)
```

<!--
Let's look at a sample of our data.
-->

```{r, include=FALSE}
head(df, n=20)
summary(df)
```

<!--
# Data Cleaning
-->

```{r, include=FALSE}
# Remove HTML Tags
df = df %>% 
  mutate(en = gsub("<.*?>", "", en))

# Convert into tidytext format
text_df <- df %>%
  select(id, status, en) %>%
  unnest_tokens(word, en)

## Remove stopwords
custom_stop_words = data.frame(word=c("loan", "business"))
text_df <- text_df %>%
  anti_join(stop_words, by=c("word"="word")) %>%
  anti_join(custom_stop_words, by=c("word"="word")) %>%
  arrange(id)

# Stem words
#library(SnowballC)
#df = df %>% 
#  mutate(en = wordStem(en))
```


<!-- 
# Feature Engineering

## Latent Dirichlet Allocation

Let's use a technique called Latent Dirichlet Allocation (LDA) to extract the topics from each document.
-->

```{r, include=FALSE}
# Count each word in each document.
word_counts = text_df %>%
  group_by(id, word) %>%
  summarize(count = n())
```


```{r, include=FALSE}
# Create a document term matrix
dtm = word_counts %>% cast_dtm(id, word, count)

# Remove sparse terms from the document term matrix.
library(tm)
dtm2.nosparse <- removeSparseTerms(dtm, 0.9995)

rowTotals <- apply(dtm2.nosparse, 1, sum) #Find the sum of words in each Document
which(rowTotals==0)
dtm.new   <- dtm2.nosparse[rowTotals> 0, ] 
```

<!--
Run the LDA model.
-->

```{r, include=FALSE}
num_topics = 12

# Because the LDA model can take quite a few minutes to run, and because I run this script over and over again
# checking its knitr output, I don't want to run LDA every single time. 
runModel = FALSE
if (runModel == TRUE) {
  # Run the model
  lda <- LDA(dtm.new, k = num_topics, control = list(seed = 1234))
  
  # Name each topic
  t = terms(lda, k=4)
  topic_names = apply(t, 2, function(x) paste(x, collapse = "_"))
  
  lda_beta <- tidy(lda, matrix = "beta")
  lda_gamma <- tidy(lda, matrix = "gamma")
  lda_gamma$document = as.integer(lda_gamma$document)
  
  # Save output
  readr::write_csv(beta, sprintf("beta_%d.csv", num_topics))
  readr::write_csv(lda_gamma, sprintf("gamma_%d.csv", num_topics))
  readr::write_csv(as.data.frame(topic_names), sprintf("topicnames_%d.csv", num_topics))
  
} else {
  # Read the output from a previous run
  lda_beta = readr::read_csv(sprintf("beta_%d.csv", num_topics))
  lda_gamma = readr::read_csv(sprintf("gamma_%d.csv", num_topics))
  topic_names = t(readr::read_csv(sprintf("topicnames_%d.csv", num_topics)))
}

tn = data.frame(id=1:12, topic_name = as.character(t(topic_names)))
tn$topic_name = as.character(tn$topic_name)
tn$topic_name = sprintf("%02d: %s", 1:12, tn$topic_name)
  
```

<!--
Add the resulting document topic probabilities to the `df` dataframe.
-->

```{r, include=FALSE}
lda_gamma_new = lda_gamma %>% spread(topic, gamma)

df_new  = df %>% left_join(lda_gamma_new, by=c("id" = "document"))
library(data.table)
setnames(df_new, old=sprintf("%d", c(1:12)), new=sprintf("topic %d: %s", c(1:12), topic_names))
```



# Data Description

The data is collected from [build.kiva](http://build.kiva.org/), Kiva's website for providing snapshots of their data from time to time. In the full dataset, about 98% of loans are repaid and 2% defaulted. In this case study, we look at only a sample of the data, where the split between repaid and defaulted is closer to 50%-50%.

Let's look at our sample to understand the size, shape, values, and patterns in the variables. The dataset inclues `r ncol(df)` variables, named: `r colnames(df)`. Most the names of the variables are self-describing. The `en` variable is the text variable, i.e., the personal story of the loan seeker, and will be our main source of investigation. There are `r nrow(df)` records/rows/loans in our sample.




```{r, eval=FALSE}
# Let's look at a few of the records in full.
# NEver got this to work on my machine, for some reason.
library(dplyr)
library(knitr)
sample = df %>%
  slice(c(1, 5000, 6009, 444, 7322)) %>%
  select(-en, everything()) %>%
  select(-id) %>%
  mutate(en = gsub("\\\r", " ", en)) %>% 
  mutate(en = gsub("\\\n", "", en))


library(kableExtra)
kable(sample, "latex") %>%
  kable_styling(font_size = 7) %>%
  column_spec(7, width = "15em")
```





<P style="page-break-before: always">
\newpage


## Variable: sector

The first variable in the dataset is `sector`. Let's look at how many loans are in each sector, and tabulate how many have paid and how many have defaulted.

```{r fig.height=4}
qplot(sector, data=df, geom="bar", fill=status, xlab="sector")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) 
```

\vspace{20pt}
<br/>
<hr/>

```{r}
kable(df %>%
  group_by(sector, status) %>%
  summarize(count=n()) %>%
  spread(status, count) %>%
  mutate(total = defaulted + paid), "latex", booktab=TRUE) %>%
  kable_styling(full_width=TRUE, latex_options = c("striped", "scale_down"))
```




<P style="page-break-before: always">
\newpage


## Variable: country

Let's do the same for the `country` variable: cross tabulation table, and a graphical representation.


```{r fig.height=2.5}
qplot(country, data=df, geom="bar", fill=status)
```


\vspace{20pt}
<br/>
<hr/>

```{r}
kable(df %>%
  group_by(country, status) %>%
  summarize(count=n()) %>%
  spread(status, count) %>%
  mutate(total = defaulted + paid), "latex", booktab=TRUE) %>%
  kable_styling(full_width=TRUE, latex_options = c("striped", "scale_down"))
```


## Variable: gender


```{r fig.height=2.5}
qplot(gender, data=df, geom="bar", fill=status)
```


\vspace{20pt}
<br/>
<hr/>

```{r}
kable(df %>%
  group_by(gender, status) %>%
  summarize(count=n()) %>%
  spread(status, count) %>%
  mutate(total = defaulted + paid), "latex", booktab=TRUE) %>%
  kable_styling(full_width=TRUE, latex_options = c("striped", "scale_down"))
```



<P style="page-break-before: always">
\newpage
## Variable: nonpayment

The nonpayment variable captures who is liable if a loan defaults: the lender, or the partner.


```{r fig.height=4}
qplot(nonpayment, data=df, geom="bar", fill=status)
```

\vspace{20pt}
<br/>
<hr/>

```{r}
kable(df %>%
  group_by(nonpayment, status) %>%
  summarize(count=n()) %>%
  spread(status, count) %>%
  mutate(total = defaulted + paid), "latex", booktab=TRUE) %>%
  kable_styling(full_width=TRUE, latex_options = c("striped", "scale_down"))
```





<P style="page-break-before: always">
\newpage
## Variable: loan_amount

Since the `loan_amount` variable is numeric, we can look at a density plot.

```{r fig.height=2.5}
df %>% 
  ggplot(aes(loan_amount)) +
  geom_density(fill = "blue", alpha=0.6) 
```

We can show a separate density for `status=defaulted` and `status=paid`.

```{r fig.height=2.5}
df %>% 
  ggplot(aes(loan_amount, colour=status, fill=status)) +
  geom_density(alpha=0.1)
```

And we can even show a "filled" density plot:

```{r fig.height=2.5}
df %>% 
  ggplot(aes(loan_amount, colour=status, fill=status)) +
  geom_density(alpha=0.1, position="fill") 
```

```{r, include=FALSE}
df$loan_amount.cut = cut(df$loan_amount, breaks=c(0, 300, 600, 900, 1500))
addmargins(table(df$loan_amount.cut, df$status, dnn=c("loan_amount.cut", "status")))
```





<P style="page-break-before: always">
\newpage
## Variable: en

The `en` variable is raw English text, and there's lots of ways we can look at it.

### Length

First, let's look at a density plot of the length (number of characters/letters).

```{r fig.height=2.5}
df %>%
  mutate(en_length = nchar(en)) %>%
  ggplot(aes(en_length, colour=status, fill=status)) +
  geom_density(alpha=0.1) +
  labs(x = "Number of characters in `en`")
```

### Top Words

Let's look at the top (i.e, most frequent) words.

```{r rows.print=20}
kable(text_df %>% group_by(word) %>%
  summarize(count=n()) %>%
  mutate(freq = count / sum(count)) %>%
  arrange(desc(count)) %>%
  top_n(20), "latex", booktab=TRUE) %>%
  kable_styling(full_width=TRUE, latex_options = c("striped", "scale_down"))
```


<P style="page-break-before: always">
\newpage

### Most Biased Words

Now, let's see which words are more biased towards being `paid` or `defaulted`, using the log odds ratio metric.

```{r}
status_words_count = text_df %>% group_by(status, word) %>%
  summarize(count=n()) %>%
  arrange(desc(count))

log_ratios = status_words_count %>% 
  spread (status, count) %>%
  select(-`<NA>`) %>%
  mutate(defaulted = ifelse(is.na(defaulted), 0, defaulted)) %>%
  mutate(paid = ifelse(is.na(paid), 0, paid)) %>%
  mutate(total=defaulted+paid) %>%
  mutate(log_ratio = log2(paid/defaulted)) 
```

```{r, fig.height=4}
log_ratios %>%
  filter(total > 500) %>%
  group_by(log_ratio < 0) %>%
  top_n(15, abs(log_ratio)) %>%
  ungroup() %>%
  mutate(word = reorder(word, log_ratio)) %>%
  ggplot(aes(word, log_ratio, fill = log_ratio < 0)) +
  geom_col() +
  coord_flip() +
  ylab("log odds ratio") +
  scale_fill_discrete(name = "", labels = c("paid", "default"))
```


Let's look at a tabular version of the same data above, first focusing on the words that are biased towards `paid`:

```{r}
kable(log_ratios %>%
  filter(total > 500) %>%
  arrange(desc(log_ratio)) %>%
  top_n(17), "latex", booktab=TRUE) %>%
  kable_styling(full_width=TRUE, latex_options = c("striped", "scale_down"))
```


<P style="page-break-before: always">
\newpage


And those that are biased towards `default`:

```{r rows.print=20}
kable(log_ratios %>%
  filter(total > 500) %>%
  arrange((log_ratio)) %>%
  top_n(-20), "latex", booktab=TRUE) %>%
  kable_styling(full_width=TRUE, latex_options = c("striped", "scale_down"))
```

<!--
Let's use the TF-IDF metric to see which words are the most "important":
-->

```{r, eval=FALSE}
book_words <- text_df %>%
  select(-status) %>%
  count(id, word, sort = TRUE) %>%
  ungroup()

book_words %>% arrange(desc(n))

total_words <- book_words %>% 
  group_by(id) %>% 
  summarize(total = sum(n))
total_words %>% arrange(desc(total))

book_words <- left_join(book_words, total_words)

freq_by_rank <- book_words %>% 
  group_by(id) %>% 
  mutate(rank = row_number(), 
         `term frequency` = n/total)
book_words_tfidf <- book_words %>%
  bind_tf_idf(word, id, n)

book_words_tfidf %>%
  arrange(desc(tf_idf))
```







<P style="page-break-before: always">
\newpage


## LDA Topics

We used a techinque called Latent Dirichlet Allocation (LDA) to automatically uncover the topics from the documents. We told LDA to discover the `12` most important topics in the documents; LDA will also tell us which topics are in which documents.

### LDA Top Terms Per Topic

First, let's look at the top terms (words) in each discovered topic.

```{r,fig.width=10,fig.height=11}
ap_top_terms <- lda_beta %>%
  group_by(topic) %>%
  top_n(10, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)

ap_top_terms %>%
  mutate(term = reorder(term, beta)) %>%
  left_join(tn, by=c("topic" = "id")) %>% 
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic_name, scales = "free", ncol=3) +
  coord_flip()
```


<P style="page-break-before: always">
\newpage

### Documents per LDA Topic

Next, let's look at how many documents have each topic.

```{r}
topic_totals = lda_gamma %>%
  left_join(df, by=c("document" = "id")) %>%
  select(c(-en)) %>% 
  filter(gamma >= 0.05) %>%
  group_by(topic, status) %>% 
  summarize(count=n()) %>%
  spread(status, count) %>%
  mutate(total = defaulted + paid) %>% 
  left_join(tn, by=c("topic" = "id")) %>%
  select(topic, topic_name, everything())
```

```{r fig.height=5}
tmp_gathered = topic_totals %>% 
  select(topic, topic_name, defaulted, paid) %>% 
  gather(Status, Value, defaulted, paid)

ggplot(tmp_gathered, aes(x=topic_name, y=Value, fill=Status)) + 
  geom_bar(stat="identity") +  
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) 
```

```{r}
kable(topic_totals, "latex", booktab=TRUE) %>%
  kable_styling(full_width=TRUE, latex_options = c("striped", "scale_down"))
```



<P style="page-break-before: always">
\newpage


# Building a Classifier Model

Now that we have explored the data, it’s time to dive deeper. Which variable(s) are the biggest predictors of `status`? This is where classifier models shine. They can tell us exactly how all the variables relate to each other, and which are most important.
 
A decision tree is a popular classifier model in analytics. Here, the decision tree is automatically created by a machine learning algorithm as it learns simple decision rules from the data. These automatically-learned rules can then be used to both understand the variables and to predict future data. A big advantage of decision trees over other classifier models is that they are relatively simple for humans to understand and interpret.
 
A decision tree consists of nodes. Each node splits the data according to a rule. A rule is based on a variable in the data. For example, a rule might be “Age greater than 30.” In this case, the node splits the data by the age variable; those passengers that satisfy the rule (i.e., are greater than 30) follow the left path out of the node; the rest follow the right path out of the node. In this way, paths from the root node down to leaf nodes are created, describing the fate of certain types of passengers.
 
A decision tree path always starts with a root node (node number 1), which contains the most important splitting rule. Each subsequent node contains the next most important rule. After the decision tree is automatically created by the machine learning algorithm, one can use the decision tree to classify an individual by simply following a path: start at the root node and apply each rule to follow the appropriate path until you hit an end.
 
When creating a decision tree from data, the analyst can specify the number of nodes for the machine learning algorithm to create. More nodes leads to a more accurate model, at the cost of a more complicated and harder-to-interpret model. Likewise, fewer nodes usually leads to a less accurate model, but the model is easier to understand and interpret. 
 
 
 
 
<P style="page-break-before: always">
\newpage


# A Prediction Model without the Text

First, as a baseline, let's train a decision tree classifier model without using any of the text or topics. Here is a graphical depiction of the model after it has been trained:

```{r fig.height=3}
set.seed(123)
# Don't want to use either of these for prediction, and the - sign doesn't work
# with rpart forumulas.
df_notext = subset(df_new, select=c(status, sector, country, gender, loan_amount, nonpayment))

# Split the data into training and testing.
train_notext <- sample_frac(df_notext, 0.8)
test_notext <- setdiff(df_notext, train_notext)


# Let's train the model.
form = as.formula(status ~ .)
tree <- rpart(form, train_notext, method="class")
rpart.plot(tree, extra=2)
```

\vspace{20pt}

Now, let's see how accurate the model is. We'll use some never-before-seen data (called _testing data_). We'll give the testing data to the classifier, ask it to make a prediction (i.e., whether the borrower will pay or not), and then we'll see if the classifier is correct. 

The following table summarizes the predictions of the classifier.

```{r}
predicted = predict(tree, test_notext, type="class")
actual = test_notext$status
preds = data.frame((table(predicted, actual)))
kable(preds, "latex", booktab=TRUE) %>%
  kable_styling(full_width=TRUE, latex_options = c("striped", "scale_down"))
```

That is, the model predicted `defaulted` 50 times correctly, and 24 times incorrectly. It also predicted `paid` correctly 120 times, and 39 times incorrectly.

Let's check the accuracy and other metrics of the classifier on the testing data.

```{r}
print(sprintf("Accuracy:    %.3f", Accuracy(y_true=actual, y_pred=predicted)))
print(sprintf("Precision:   %.3f", Precision(y_true=actual, y_pred=predicted)))
print(sprintf("Recall:      %.3f", Recall(y_true=actual, y_pred=predicted)))
print(sprintf("F1 Score:    %.3f", F1_Score(predicted, actual)))
print(sprintf("Sensitivity: %.3f", Sensitivity(y_true=actual, y_pred=predicted)))
print(sprintf("Specificity: %.3f", Specificity(y_true=predicted, y_pred=actual)))
```





<P style="page-break-before: always">
\newpage


# A Prediction Model with the Text

Now, let's build the same decision tree classifier model as before, except now, let's include the LDA topics, which were built from the text. (Note: there are many _other_ textual features we could include in this model: individual words, clusters, etc. However, we'll keep it simple for now.)

```{r fig.height=3}
set.seed(123)
# Don't want to use either of these for prediction, and the - sign doesn't work
# with rpart forumulas.
df_text = subset(df_new, select=c(-id, -en))

# Split the data into training and testing.
train_text <- sample_frac(df_text, 0.8)
test_text <- setdiff(df_text, train_text)


# Let's create the model.
form = as.formula(status ~ .)
tree <- rpart(form, train_text, method="class")
rpart.plot(tree, extra=2)
```

\vspace{20pt}

Confusion matrix:

```{r}
predicted = predict(tree, test_text, type="class")
actual = test_text$status
preds.text = data.frame((table(predicted, actual)))
kable(preds.text, "latex", booktab=TRUE) %>%
  kable_styling(full_width=TRUE, latex_options = c("striped", "scale_down"))
```


\vspace{20pt}

Metrics:

```{r}
print(sprintf("Accuracy:    %.3f", Accuracy(y_true=actual, y_pred=predicted)))
print(sprintf("Precision:   %.3f", Precision(y_true=actual, y_pred=predicted)))
print(sprintf("Recall:      %.3f", Recall(y_true=actual, y_pred=predicted)))
print(sprintf("F1 Score:    %.3f", F1_Score(predicted, actual)))
print(sprintf("Sensitivity: %.3f", Sensitivity(y_true=actual, y_pred=predicted)))
print(sprintf("Specificity: %.3f", Specificity(y_true=predicted, y_pred=actual)))
```

<P style="page-break-before: always">
\newpage


# Appendix: Further Reading

- [Kiva.org](https://www.kiva.org/). Kiva's homepage.
- [Build.Kiva](http://build.kiva.org/). Kiva data dumps and data description.
 
