{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of the Marketing Dataset\n",
    "### Who Bought the Product?\n",
    "- Stephen W. Thomas\n",
    "- Used for MMAI 869"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-05 09:43:41.040090\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "import sklearn.metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import itertools\n",
    "import scipy\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/marketing.csv')\n",
    "df.info()\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['Age', 'Income']]\n",
    "y = df['Bought']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=42, criterion=\"entropy\",\n",
    "                             max_depth=3, max_leaf_nodes=5)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_dt = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the Model to Predict Someone New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict_proba([[2, 2]])\n",
    "clf.predict([[2, 2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Parameters\n",
    "\n",
    "Surpisingly, sci-kit learn does not have a function to print the decision tree in text format. (It does have a way to graphical render the three, which we'll do later.) For now, we'll just print a few stats about the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.tree_.node_count)\n",
    "print(clf.tree_.impurity)\n",
    "print(clf.tree_.children_left)\n",
    "print(clf.tree_.threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred_dt, target_names=class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
    "\n",
    "treeclf = DecisionTreeClassifier(splitter='best', presort=True, class_weight=None, random_state=42)\n",
    "parameters = {'criterion':('gini', 'entropy'), 'max_depth':[2, 4, 6, 8, 10], 'min_samples_split':[2, 10, 50], 'min_samples_leaf':[1, 5, 10],\n",
    "             'max_features':[None, 'auto'], 'max_leaf_nodes':[None, 5, 10, 50], 'min_impurity_decrease':[0, 0.1, 0.2]}\n",
    "cv_clf = GridSearchCV(treeclf, parameters, scoring='roc_auc', cv=5, return_train_score=True)\n",
    "%time cv_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_clf.best_params_\n",
    "cv_clf.best_score_\n",
    "cv_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(10, 10));\n",
    "ax = plt.subplot(1, 1, 1);\n",
    "plot_boundaries(X_train, X_test, y_train, y_test, cv_clf.best_estimator_, \"Decision Tree\", ax, hide_ticks=False, show_train=False)\n",
    "ax.set_xlabel(\"Age\", fontsize=22)\n",
    "ax.set_ylabel(\"Income\", fontsize=22)\n",
    "plt.tight_layout();\n",
    "plt.savefig('out/marketing-dt-decision-grid-test.png', transparent=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb = gnb.fit(X_train, y_train)\n",
    "gnb\n",
    "\n",
    "y_pred_gnb = gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb.theta_ # Mean of each feature per class\n",
    "gnb.sigma_ # Variance of each feature per class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred_gnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_gnb, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy = {:.2f}\".format(accuracy_score(y_test, y_pred_gnb)))\n",
    "print(\"Kappa = {:.2f}\".format(cohen_kappa_score(y_test, y_pred_gnb)))\n",
    "print(\"F1 Score = {:.2f}\".format(f1_score(y_test, y_pred_gnb)))\n",
    "print(\"Log Loss = {:.2f}\".format(log_loss(y_test, y_pred_gnb)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_knn = knn_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_clf.effective_metric_\n",
    "knn_clf.effective_metric_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_knn, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy = {:.2f}\".format(accuracy_score(y_test, y_pred_knn)))\n",
    "print(\"Kappa = {:.2f}\".format(cohen_kappa_score(y_test, y_pred_knn)))\n",
    "print(\"F1 Score = {:.2f}\".format(f1_score(y_test, y_pred_knn)))\n",
    "print(\"Log Loss = {:.2f}\".format(log_loss(y_test, y_pred_knn)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM - Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_clf = SVC(kernel=\"linear\", C=0.025)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_svm = svm_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf.n_support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf.support_vectors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf.dual_coef_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf.intercept_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_svm, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy = {:.2f}\".format(accuracy_score(y_test, y_pred_svm)))\n",
    "print(\"Kappa = {:.2f}\".format(cohen_kappa_score(y_test, y_pred_svm)))\n",
    "print(\"F1 Score = {:.2f}\".format(f1_score(y_test, y_pred_svm)))\n",
    "print(\"Log Loss = {:.2f}\".format(log_loss(y_test, y_pred_svm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X)\n",
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get the separating hyperplane\n",
    "w = svm_clf.coef_[0]\n",
    "a = -w[0] / w[1]\n",
    "xx = np.linspace(-5, 5)\n",
    "yy = a * xx - (svm_clf.intercept_[0]) / w[1]\n",
    "\n",
    "# plot the parallels to the separating hyperplane that pass through the\n",
    "# support vectors (margin away from hyperplane in direction\n",
    "# perpendicular to hyperplane). This is sqrt(1+a^2) away vertically in\n",
    "# 2-d.\n",
    "margin = 1 / np.sqrt(np.sum(svm_clf.coef_ ** 2))\n",
    "yy_down = yy - np.sqrt(1 + a ** 2) * margin\n",
    "yy_up = yy + np.sqrt(1 + a ** 2) * margin\n",
    "\n",
    "# plot the line, the points, and the nearest vectors to the plane\n",
    "plt.figure(figsize=(4, 3))\n",
    "plt.clf()\n",
    "plt.plot(xx, yy, 'k-')\n",
    "plt.plot(xx, yy_down, 'k--')\n",
    "plt.plot(xx, yy_up, 'k--')\n",
    "\n",
    "plt.scatter(svm_clf.support_vectors_[:, 0], svm_clf.support_vectors_[:, 1], s=80,\n",
    "            facecolors='none', zorder=10, edgecolors='k')\n",
    "plt.scatter(X[:, 0], X[:, 1], c=Y, zorder=10, cmap=plt.cm.Paired,\n",
    "            edgecolors='k')\n",
    "\n",
    "plt.axis('tight')\n",
    "x_min = -4.8\n",
    "x_max = 4.2\n",
    "y_min = -6\n",
    "y_max = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(10, 10));\n",
    "ax = plt.subplot(1, 1, 1);\n",
    "plot_boundaries(X_train, X_test, y_train, y_test, svm_clf, \"SVM (Linear)\", ax, hide_ticks=False, show_train=False)\n",
    "ax.set_xlabel(\"Age\", fontsize=22)\n",
    "ax.set_ylabel(\"Income\", fontsize=22)\n",
    "plt.tight_layout();\n",
    "plt.savefig('out/marketing-svm-decision-test.png', transparent=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting with Different Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"Linear C=0.0025\", \"Linear C=0.25\", \"Linear C=25\"]\n",
    "\n",
    "classifiers = [\n",
    "    SVC(kernel=\"linear\", C=0.0025),\n",
    "    SVC(kernel=\"linear\", C=0.25),\n",
    "    SVC(kernel=\"linear\", C=25),\n",
    "]\n",
    "\n",
    "rng = np.random.RandomState(2)\n",
    "\n",
    "figure = plt.figure(figsize=(27, 10));\n",
    "i = 1\n",
    "\n",
    "# iterate over classifiers\n",
    "for name, clf_tmp in zip(names, classifiers):\n",
    "    ax = plt.subplot(1, 3, i);\n",
    "    clf_tmp.fit(X_train, y_train);\n",
    "    plot_boundaries(X_train, X_test, y_train, y_test, clf_tmp, name, ax, hide_ticks=True, show_train=False);\n",
    "    i += 1\n",
    "\n",
    "plt.tight_layout();\n",
    "plt.savefig('out/marketing-svm-decision-test-all-c.png', transparent=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"Poly 2\", \"Poly 3\", \"Poly 4\"]\n",
    "\n",
    "classifiers = [\n",
    "    SVC(kernel=\"poly\", degree=2, C=0.25),\n",
    "    SVC(kernel=\"poly\", degree=3, C=1),\n",
    "    SVC(kernel=\"poly\", degree=4, C=1),\n",
    "]\n",
    "\n",
    "rng = np.random.RandomState(2)\n",
    "\n",
    "figure = plt.figure(figsize=(27, 10));\n",
    "i = 1\n",
    "\n",
    "# iterate over classifiers\n",
    "for name, clf_tmp in zip(names, classifiers):\n",
    "    ax = plt.subplot(1, 3, i);\n",
    "    clf_tmp.fit(X_train, y_train);\n",
    "    plot_boundaries(X_train, X_test, y_train, y_test, clf_tmp, name, ax, hide_ticks=True, show_train=False);\n",
    "    i += 1\n",
    "\n",
    "plt.tight_layout();\n",
    "plt.savefig('out/marketing-svm-decision-test-all-poly.png', transparent=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"RBF G=0.05\", \"RBF G=0.5\", \"RBF G=5.0\"]\n",
    "\n",
    "classifiers = [\n",
    "    SVC(kernel=\"rbf\", gamma=0.05, C=1),\n",
    "    SVC(kernel=\"rbf\", gamma=0.5, C=1),\n",
    "    SVC(kernel=\"rbf\", gamma=5.0, C=1),\n",
    "]\n",
    "\n",
    "rng = np.random.RandomState(2)\n",
    "\n",
    "figure = plt.figure(figsize=(27, 10));\n",
    "i = 1\n",
    "\n",
    "# iterate over classifiers\n",
    "for name, clf_tmp in zip(names, classifiers):\n",
    "    ax = plt.subplot(1, 3, i);\n",
    "    clf_tmp.fit(X_train, y_train);\n",
    "    plot_boundaries(X_train, X_test, y_train, y_test, clf_tmp, name, ax, hide_ticks=True, show_train=False);\n",
    "    i += 1\n",
    "\n",
    "plt.tight_layout();\n",
    "plt.savefig('out/marketing-svm-decision-test-all-rbf.png', transparent=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "nn_clf = MLPClassifier(solver='lbfgs', activation='relu', alpha=1e-3, \n",
    "                       hidden_layer_sizes=(3), random_state=1, verbose=True)\n",
    "nn_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_nn = nn_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_clf.loss_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_clf.n_layers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = nn_clf.coefs_ # The ith element in the list represents the weight matrix corresponding to layer i.\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = nn_clf.intercepts_ # The ith element in the list represents the bias vector corresponding to layer i + 1.\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_clf.out_activation_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_clf.predict_proba([[0.5, 1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, y_pred_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_nn, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy = {:.2f}\".format(accuracy_score(y_test, y_pred_nn)))\n",
    "print(\"Kappa = {:.2f}\".format(cohen_kappa_score(y_test, y_pred_nn)))\n",
    "print(\"F1 Score = {:.2f}\".format(f1_score(y_test, y_pred_nn)))\n",
    "print(\"Log Loss = {:.2f}\".format(log_loss(y_test, y_pred_nn)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "small_sklearn_kernel",
   "language": "python",
   "name": "small_sklearn_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
